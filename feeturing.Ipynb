{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "\n",
    "# Étape 1 : Charger les bases ETRETAT_PM et ETRETAT_PP\n",
    "# Load ETRETAT_PM and ETRETAT_PP datasets\n",
    "etretat_pm = pd.read_csv('DE_ETRETAT_RENTABILITE_SIEGE_PM_2024_11_14$22_41_12.csv', sep=';')\n",
    "etretat_pp = pd.read_csv('DE_ETRETAT_RENTABILITE_SIEGE_PP_2024_11_14$23_07_34.csv', sep=';')\n",
    "\n",
    "# Étape 2 : Garder uniquement les colonnes nécessaires\n",
    "# Keep only relevant columns\n",
    "columns_to_keep = ['cd_tiers', 'CIR_RWA', 'CIR_CNR_FLUX']\n",
    "etretat_pm = etretat_pm[columns_to_keep].copy()\n",
    "etretat_pp = etretat_pp[columns_to_keep].copy()\n",
    "\n",
    "# Étape 3 : Renommer les colonnes pour chaque base\n",
    "# Rename columns for each dataset\n",
    "etretat_pm.rename(columns={\n",
    "    'CIR_RWA': 'RWA_CNR_PM',\n",
    "    'CIR_CNR_FLUX': 'CNR_CNR_PM'\n",
    "}, inplace=True)\n",
    "\n",
    "etretat_pp.rename(columns={\n",
    "    'CIR_RWA': 'RWA_CNR_PP',\n",
    "    'CIR_CNR_FLUX': 'CNR_CNR_PP'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ajouter un préfixe pour différencier les deux datasets\n",
    "# Add prefix to differentiate datasets\n",
    "etretat_pm.rename(columns=lambda x: f\"PM_{x}\" if x != 'cd_tiers' else x, inplace=True)\n",
    "etretat_pp.rename(columns=lambda x: f\"PP_{x}\" if x != 'cd_tiers' else x, inplace=True)\n",
    "\n",
    "# Étape 4 : Groupby sur 'cd_tiers' pour obtenir une ligne unique par client\n",
    "# Groupby on 'cd_tiers' to have one unique row per client\n",
    "etretat_pm_grouped = etretat_pm.groupby('cd_tiers').sum().reset_index()\n",
    "etretat_pp_grouped = etretat_pp.groupby('cd_tiers').sum().reset_index()\n",
    "\n",
    "# Étape 5 : Importer la base Base_VPVD_PNB\n",
    "# Load the base Base_VPVD_PNB\n",
    "base_vpvd_pnb = pd.read_csv('Base_VPVD_PNB.csv', sep=';')\n",
    "\n",
    "# Étape 6 : Merge des bases avec Base_VPVD_PNB\n",
    "# Merge the datasets with Base_VPVD_PNB\n",
    "# Merge avec ETRETAT_PP\n",
    "# Merge with ETRETAT_PP\n",
    "base_merged = base_vpvd_pnb.merge(\n",
    "    etretat_pp_grouped,\n",
    "    left_on='PM_CD_TIERS',\n",
    "    right_on='cd_tiers',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge avec ETRETAT_PM\n",
    "# Merge with ETRETAT_PM\n",
    "base_merged = base_merged.merge(\n",
    "    etretat_pm_grouped,\n",
    "    left_on='PP_CD_TIERS',\n",
    "    right_on='cd_tiers',\n",
    "    how='left',\n",
    "    suffixes=('_pp', '_pm')\n",
    ")\n",
    "\n",
    "# Étape 7 : Nettoyer les colonnes inutiles\n",
    "# Drop unnecessary columns\n",
    "base_merged.drop(columns=['cd_tiers_pp', 'cd_tiers_pm'], inplace=True)\n",
    "\n",
    "# Étape 8 : Exporter le fichier final\n",
    "# Export the final file\n",
    "base_merged.to_csv('Base_VPVD_PNB_Final.csv', sep=';', index=False)\n",
    "\n",
    "print(\"Script terminé avec succès, fichier exporté.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger les données\n",
    "# Base_VPVD_DAT_R = pd.read_csv(\"chemin_vers_votre_fichier.csv\")  # Exemple d'import\n",
    "\n",
    "# Étape 1: Calcul de `SUM_RWA_PM`\n",
    "Base_VPVD_DAT_R[\"SUM_RWA_PM\"] = Base_VPVD_DAT_R.groupby(\"PP_CD_TIERS\")[\"PM_CIR_RWA\"].transform(\"sum\")\n",
    "\n",
    "# Étape 2: Calcul de `RATIO DE RWA`\n",
    "def calculate_ratio(row):\n",
    "    if row[\"NB_PM par PP\"] == 1:\n",
    "        return 1\n",
    "    elif pd.isna(row[\"PP_CD_TIERS\"]):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return row[\"PM_CIR_RWA\"] / row[\"SUM_RWA_PM\"]\n",
    "\n",
    "Base_VPVD_DAT_R[\"RATIO_DE_RWA\"] = Base_VPVD_DAT_R.apply(calculate_ratio, axis=1)\n",
    "\n",
    "# Étape 3: Calcul de `ALLOCATION RWA PP`\n",
    "Base_VPVD_DAT_R[\"ALLOCATION_RWA_PP\"] = Base_VPVD_DAT_R[\"PM_CIR_RWA\"] * Base_VPVD_DAT_R[\"RATIO_DE_RWA\"]\n",
    "\n",
    "# Étape 4: Calcul de `SOMME RWA VD par PM`\n",
    "Base_VPVD_DAT_R[\"SOMME_RWA_VD_par_PM\"] = Base_VPVD_DAT_R.groupby(\"PM_CD_TIERS\")[\"ALLOCATION_RWA_PP\"].transform(\"sum\")\n",
    "\n",
    "# Exporter le résultat (si nécessaire)\n",
    "# Base_VPVD_DAT_R.to_csv(\"chemin_vers_le_fichier_de_sortie.csv\", index=False)\n",
    "\n",
    "# Affichage des premières lignes pour vérifier le résultat\n",
    "print(Base_VPVD_DAT_R.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger votre fichier de données\n",
    "df = pd.read_csv(\"votre_fichier.csv\")\n",
    "\n",
    "# Étape 1 : Créer une colonne pour le PNB non distribué\n",
    "# Ventiler 38 MEUR sur les clients \"PRO VP Double Relation\" au prorata de leur PNB\n",
    "total_pnb = df.loc[df[\"PM_NATURE_RELATION\"] == \"PRO VP Double Relation\", \"PM_PNB_NATIF_ART\"].sum()\n",
    "df[\"PNB_PNB_NON_DISTRIBUE\"] = df.apply(\n",
    "    lambda x: (38_000_000 * x[\"PM_PNB_NATIF_ART\"] / total_pnb)\n",
    "    if x[\"PM_NATURE_RELATION\"] == \"PRO VP Double Relation\" else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Étape 2 : Créer une colonne pour le PNB hors marchés\n",
    "# Ventiler XXX MEUR sur toutes les PM au prorata de leur PNB\n",
    "total_pnb_general = df[\"PM_PNB_NATIF_ART\"].sum()\n",
    "df[\"PNB_HORS_MARCHES\"] = df[\"PM_PNB_NATIF_ART\"].apply(lambda x: (XXX * x / total_pnb_general))\n",
    "\n",
    "# Étape 3 : Créer une colonne \"PNB_VPVD\" (somme des colonnes PNB)\n",
    "df[\"PNB_VPVD\"] = df[\"PM_PNB_NATIF_ART\"] + df[\"SOMME_PNB_VD_PAR_PM\"]\n",
    "\n",
    "# Étape 4 : Créer une colonne \"RWA_VPVD\" (somme des colonnes RWA)\n",
    "df[\"RWA_VPVD\"] = df[\"PM_CIR_RWA\"] + df[\"SOMME_RWA_VD\"]\n",
    "\n",
    "# Étape 5 : Créer une colonne \"CNR_VPVD\" (somme des colonnes CNR)\n",
    "df[\"CNR_VPVD\"] = df[\"PM_CIR_CNR\"] + df[\"SOMME_CNR_VD\"]\n",
    "\n",
    "# Enregistrer le fichier final\n",
    "df.to_csv(\"Data_processing/VPVD_Final.csv\", index=False)\n",
    "\n",
    "print(\"Le fichier 'VPVD_Final.csv' a été généré avec succès.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exemple de DataFrame\n",
    "data = {'text': [\n",
    "    \"Bonjour le monde, Python est incroyable\",\n",
    "    \"Données et visualisation avec des graphiques simples\",\n",
    "    \"Le monde de la data est fascinant\",\n",
    "    \"Python rend les analyses de données accessibles\"\n",
    "]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Combiner toutes les lignes en un seul texte\n",
    "text = \" \".join(df['text'])\n",
    "\n",
    "# Définir une liste de mots inutiles (stopwords)\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"le\", \"de\", \"et\", \"la\", \"les\", \"des\", \"est\", \"avec\"])  # Ajouter vos propres mots inutiles\n",
    "\n",
    "# Créer le nuage de mots\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    stopwords=stopwords,\n",
    "    colormap='viridis',\n",
    "    max_words=100\n",
    ").generate(text)\n",
    "\n",
    "# Afficher le nuage de mots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")  # Pas d'axes\n",
    "plt.title(\"Nuage de Mots des Textes\", fontsize=16)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
